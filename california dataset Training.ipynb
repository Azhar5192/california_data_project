{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1977dea-30e6-4633-bc41-1dbc10ac58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# df = pd.read_csv(r\"C:\\Users\\md747\\Downloads\\1750577806322-housing\\housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db15866c-5697-4cb0-8a34-19d1f2a9be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['income_cat'] = pd.cut(df[\"median_income\"], bins=[0, 1.5 ,3.0 , 4.5, 6.0 , np.inf], labels=[1,2,3,4,5])\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbe1bc6-0ce2-4ce4-a87c-10032c4a5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df['income_cat'].value_counts().sort_index().plot.bar(rot=0 , grid=True)\n",
    "# plt.title(\"Income Catogery Distribution\")\n",
    "# plt.xlabel(\"income_catogery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3cc624-8536-4de1-8335-f81954bc3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist(bins=50, figsize=(12,8))\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82b2195-d215-4d8c-880d-fcfb0eb3007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def train_test_split(data,test_ratio):\n",
    "#     np.random.seed(42) # set the seed for reproducibility\n",
    "#     suffled_indices = np.random.permutation(len(data)) # this return suffled indices\n",
    "#     test_set_size = int(len(data)*test_ratio)\n",
    "#     test_indices = suffled_indices[:test_set_size]\n",
    "#     train_indices = suffled_indices[test_set_size:]\n",
    "#     return data.iloc[test_indices], data.iloc[train_indices]\n",
    "    \n",
    "    \n",
    "# import numpy as np\n",
    "# def train_test_split(data,test_ratio):\n",
    "#     np.random.seed(42) # set the seed for reproducibility\n",
    "#     suffled_indices = np.random.permutation(len(data)) # this return suffled indices\n",
    "#     return data.iloc[suffled_indices[:int(len(data)*test_ratio)]], data.iloc[suffled_indices[int(len(data)*test_ratio):]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c078ba0-1ef8-4f31-b7c9-89a8cc941735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test = train_test_split(df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eb481647-0f84-4f0a-b52b-d071abfc9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "11030c74-0b03-4df2-9d6e-e8aa0c3eab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "369eaf7f-ee58-4cc9-a301-f488d9ba3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# for train_index , test_index in split.split(df, df[\"income_cat\"]):\n",
    "#     strat_train_set = df.loc[train_index]\n",
    "#     strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "39842197-cca9-4179-b8c5-fa5c74956f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strat_train_set['income_cat'].value_counts().sort_index().plot.bar(rot=0 , grid=True)\n",
    "# plt.title(\"Income Catogery Distribution\")\n",
    "# plt.xlabel(\"income_catogery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2a61d616-3193-462a-b7ab-42bc71f83ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strat_test_set['income_cat'].value_counts().sort_index().plot.bar(rot=0 , grid=True)\n",
    "# plt.title(\"Income Catogery Distribution\")\n",
    "# plt.xlabel(\"income_catogery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "518b30fa-b90f-4ee1-ae0d-4e86b0eeeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # let remove the colomn income_cat from strat_train_set and strat_test_set\n",
    "# for sett in (strat_train_set,strat_test_set):\n",
    "#     sett.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "455653bd-6a0b-4bab-b11a-f03fc08ce6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "458f7ef8-6295-4195-a7eb-5e70acfe6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_data = strat_train_set.copy() # always do operations on train set instead of test set\n",
    "# copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3c16efb9-2648-4b47-8d45-cabbb50c08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strat_train_set.plot(kind=\"scatter\" , x=\"latitude\" , y=\"longitude\" , grid=True , alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ee786c23-9ed2-4a6f-83ff-eb9f61275f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_data.plot(kind=\"scatter\" , x=\"latitude\" , y=\"longitude\" , grid=True ,  cmap=\"jet\" , c=\"median_house_value\")\n",
    "# copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "626d142d-7ad0-4e8b-bfd6-74b9fe7e3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copy_data.drop(labels=\"ocean_proximity\" , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "974e6bcd-2964-4c94-9334-3d7bc5772d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4e55e430-9916-4695-a7be-23623b81ddc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corr_matrix = copy_data.corr()\n",
    "# corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2596633f-adf1-4b35-91b4-193ca796fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "# scatter_matrix(copy_data[attributes], figsize=(15, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd179a0e-c0c8-42db-809f-b5269b601d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Focused Income vs Price Plot\n",
    "# df.plot(kind=\"scatter\", x=\"median_income\", y=\"total_bedrooms\", grid=True,alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b898d924-4e8c-4181-89cc-b2dc9756a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_data.drop()\n",
    "# df.drop(\"income_cat\",axis=1)\n",
    "# # df\n",
    "# copy_data = copy_data.drop(\"income_cat\", axis=1)\n",
    "# copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cca4e363-62ff-445c-bd75-7093e9204340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing = strat_train_set.drop(\"median_house_value\" ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "00d7abf2-beb4-40fe-aefc-b33bbd929b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_labels = strat_train_set[\"median_house_value\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9201627-b3d4-4ba8-bf1c-a785d3089520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing= housing.drop('ocean_proximity', axis=1)\n",
    "# housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "58e336bd-a435-461d-b8ab-ca6e4347e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets clean and replace Nan with appropriate data\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "# # \"mean\" – replaces with mean value\n",
    "\n",
    "# \"most_frequent\" – for the most common value (can handle categorical)\n",
    "\n",
    "# \"constant\" – fill with a fixed value using fill_value=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8a48d8ea-5b39-4561-aa71-73c4390437ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_num  = housing.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4f1a2796-57e4-4010-be75-59ad5234d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "62ec2ec4-fd77-46bb-a05b-4ff2da983e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4985053e-9521-4d8b-a63e-0b43088f7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3023291c-376a-43e3-9b1b-b17dd8e4934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# handlenig catorgeries attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6c0ca2b9-155b-4346-b810-58af3bb36a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing = pd.DataFrame(X , columns=housing_num.columns, index=housing_num.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6af52c75-4f2c-4f9b-a04f-307d17b4784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing['ocean_proximity'] = copy_data[\"ocean_proximity\"]\n",
    "\n",
    "# copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ede35e9-a02c-4f0c-91f0-da341d3c10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aff84fe3-e260-43bc-9d4a-9e7d6f147538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(housing['ocean_proximity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3b83435c-8dca-4514-b7b8-b8836166722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ocean_proximity columns into int using OrdinalEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ordinal_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# housing_cat = ordinal_encoder.fit_transform(housing[['ocean_proximity']])\n",
    "\n",
    "# categories_name = ordinal_encoder.categories_[0]\n",
    "\n",
    "# housing_cat = pd.DataFrame(housing_cat , columns=categories_name , index=housing.index)\n",
    "# housing_cat\n",
    "\n",
    "# housing_cat_1hot = cat_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "22d739fa-e197-4eb6-aea3-474d93d9ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder\tCategories have an order\t2D NumPy array\n",
    "# OneHotEncoder\tCategories are unordered\tSparse or dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3a2066a5-75c0-479f-8aae-60b53a43be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling scikit learn\n",
    "\n",
    "\n",
    "\n",
    "# copy_data = pd.concat([copy_data,housing_cat] , axis=1)\n",
    "\n",
    "# copy_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6356e985-c507-40cb-ac06-0925a1049b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler # instead of MinMaxScaler\n",
    "# # Use feature_range=(-1, 1) for models like neural networks.\n",
    "# # Sensitive to outliers — extreme values can distort the scale.\n",
    "# copy_data= copy_data.drop(['ocean_proximity'], axis=1) # delete the ocean_proximity column\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# copy_data_scaled = scaler.fit_transform(copy_data)\n",
    "\n",
    "# # copy_data_scaled # its give output in numpy so convert it into dataframe\n",
    "# copy_data_scaled = pd.DataFrame(copy_data_scaled , columns=copy_data.columns , index=copy_data.index)\n",
    "\n",
    "# copy_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7211bd-6d38-4fcc-8ecb-209fea1f2bfd",
   "metadata": {},
   "source": [
    "## *using pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f872fa29-c5c6-4353-a790-2e9154b92a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from sklearn import set_config # this convert array into dataframe automatically\n",
    "# set_config(transform_output=\"pandas\")\n",
    "\n",
    "\n",
    "\n",
    "# num_pipeline = Pipeline([\n",
    "#     (\"imputer\" , SimpleImputer(strategy=\"median\")),\n",
    "#     (\"standarised\" , StandardScaler()),\n",
    "# ])\n",
    "# # housing = pd.DataFrame(housing , columns=housing.columns, index=housing.index)\n",
    "# housing = num_pipeline.fit_transform(housing)\n",
    "# housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f444dd3-f460-4667-8bb7-36b1855d09a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m full_pipeline\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(MODEL_FILE):\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# TRAINING PHASE\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     housing = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhousing.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     housing[\u001b[33m'\u001b[39m\u001b[33mincome_cat\u001b[39m\u001b[33m'\u001b[39m] = pd.cut(housing[\u001b[33m\"\u001b[39m\u001b[33mmedian_income\u001b[39m\u001b[33m\"\u001b[39m], \n\u001b[32m     34\u001b[39m                                    bins=[\u001b[32m0.0\u001b[39m, \u001b[32m1.5\u001b[39m, \u001b[32m3.0\u001b[39m, \u001b[32m4.5\u001b[39m, \u001b[32m6.0\u001b[39m, np.inf], \n\u001b[32m     35\u001b[39m                                    labels=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m])\n\u001b[32m     36\u001b[39m     split = StratifiedShuffleSplit(n_splits=\u001b[32m1\u001b[39m, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'housing.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "MODEL_FILE = \"model.pkl\"\n",
    "PIPELINE_FILE = \"pipeline.pkl\"\n",
    "\n",
    "def build_pipeline(num_attribs, cat_attribs):\n",
    "    num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs)\n",
    "    ])\n",
    "    return full_pipeline\n",
    "\n",
    "if not os.path.exists(MODEL_FILE):\n",
    "    # TRAINING PHASE\n",
    "    housing = pd.read_csv(\"housing.csv\")\n",
    "    housing['income_cat'] = pd.cut(housing[\"median_income\"], \n",
    "                                   bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf], \n",
    "                                   labels=[1, 2, 3, 4, 5])\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "        housing.loc[test_index].drop(\"income_cat\", axis=1).to_csv('input.csv', index=False)\n",
    "        housing = housing.loc[train_index].drop(\"income_cat\", axis=1)\n",
    "\n",
    "    housing_labels = housing[\"median_house_value\"].copy()\n",
    "    housing_features = housing.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "    num_attribs = housing_features.drop(\"ocean_proximity\", axis=1).columns.tolist()\n",
    "    cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "    pipeline = build_pipeline(num_attribs, cat_attribs)\n",
    "    housing_prepared = pipeline.fit_transform(housing_features)\n",
    "\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(housing_prepared, housing_labels)\n",
    "\n",
    "    # Save model and pipeline\n",
    "    joblib.dump(model, MODEL_FILE)\n",
    "    joblib.dump(pipeline, PIPELINE_FILE)\n",
    "\n",
    "    print(\"Model trained and saved.\")\n",
    "\n",
    "else:\n",
    "    # INFERENCE PHASE\n",
    "    model = joblib.load(MODEL_FILE)\n",
    "    pipeline = joblib.load(PIPELINE_FILE)\n",
    "\n",
    "    input_data = pd.read_csv(\"input.csv\")\n",
    "    transformed_input = pipeline.transform(input_data)\n",
    "    predictions = model.predict(transformed_input)\n",
    "    input_data[\"median_house_value\"] = predictions\n",
    "\n",
    "    input_data.to_csv(\"output.csv\", index=False)\n",
    "    print(\"Inference complete. Results saved to output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d001fa-d20f-4388-b735-d5c935f6a408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
